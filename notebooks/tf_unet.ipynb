{
  "cells": [
    {
      "metadata": {
        "_uuid": "995304c1c60802126c95fefec5d2467052c6e640"
      },
      "cell_type": "markdown",
      "source": "# Summary\n\nTensorflow U-net\n\nThis notebook combines the Keras U-net from this notebook: https://www.kaggle.com/phoenigs/u-net-dropout-augmentation-stratification\n\nAnd the Tensorflow U-net code from here: https://github.com/kkweon/UNet-in-Tensorflow"
    },
    {
      "metadata": {
        "_uuid": "fa525d982fdb7e518de47cd8ec52f6ee868d312b"
      },
      "cell_type": "markdown",
      "source": "# Changelog\n- Changed uncov to uconv, but removed the dropout in the last layer\n- Corrected sanity check of predicted validation data (changed from ids_train to ids_valid)\n- Used correct mask (from original train_df) for threshold tuning (inserted y_valid_ori)"
    },
    {
      "metadata": {
        "_uuid": "ada861a85e9549dca27667692da408c5fdccbaa5"
      },
      "cell_type": "markdown",
      "source": "# About\nSince I am new to learning from image segmentation and kaggle in general I want to share my noteook.\nI saw it is similar to others as it uses the U-net approach. I want to share it anyway because:\n\n- As said, the field is new to me so I am open to suggestions.\n- It visualizes some of the steps, e.g. scaling, to learn if the methods do what I expect which might be useful to others (I call them sanity checks).\n- Added stratification by the amount of salt contained in the image.\n- Added augmentation by flipping the images along the y axes (thanks to the forum for clarification).\n- Added dropout to the model which seems to improve performance."
    },
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nfrom random import randint\n\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-white')\nimport seaborn as sns\nsns.set_style(\"white\")\n\nfrom sklearn.model_selection import train_test_split\n\nfrom skimage.transform import resize\nfrom sklearn.utils import shuffle\n\nfrom keras.preprocessing.image import load_img\n\nfrom tqdm import tqdm, tqdm_notebook",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "962c2c6775b5fcf605df8e7c59cbcabe6ba9ceaa"
      },
      "cell_type": "markdown",
      "source": "# Params and helpers"
    },
    {
      "metadata": {
        "_uuid": "e54e151245d665e42bb95d9cf2e1a33cb9440e48",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "img_size_ori = 101\nimg_size_target = 128\n\ndef upsample(img):\n    if img_size_ori == img_size_target:\n        return img\n    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n    #res = np.zeros((img_size_target, img_size_target), dtype=img.dtype)\n    #res[:img_size_ori, :img_size_ori] = img\n    #return res\n    \ndef downsample(img):\n    if img_size_ori == img_size_target:\n        return img\n    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)\n    #return img[:img_size_ori, :img_size_ori]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "530c358f2868a444e8233936996463a66c2cc4f3"
      },
      "cell_type": "markdown",
      "source": "# Loading of training/testing ids and depths\nReading the training data and the depths, store them in a DataFrame. Also create a test DataFrame with entries from depth not in train."
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_df = pd.read_csv(\"../input/train.csv\", index_col=\"id\", usecols=[0])\ndepths_df = pd.read_csv(\"../input/depths.csv\", index_col=\"id\")\ntrain_df = train_df.join(depths_df)\ntest_df = depths_df[~depths_df.index.isin(train_df.index)]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "24d7f3d982bfa582b222f012129acdda55282b6d"
      },
      "cell_type": "markdown",
      "source": "# Read images and masks\nLoad the images and masks into the DataFrame and divide the pixel values by 255."
    },
    {
      "metadata": {
        "_uuid": "b18c1f50cefd7504eae7e7b9605be3814c7cad6d",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_df[\"images\"] = [np.array(load_img(\"../input/train/images/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "86620c6a070571895f4f36ec050a25803915ed74",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_df[\"masks\"] = [np.array(load_img(\"../input/train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1137f0a009f10b5f69e4dade5f689e744e9ce1d6"
      },
      "cell_type": "markdown",
      "source": "# Calculating the salt coverage and salt coverage classes\nCounting the number of salt pixels in the masks and dividing them by the image size. Also create 11 coverage classes, -0.1 having no salt at all to 1.0 being salt only.\nPlotting the distribution of coverages and coverage classes, and the class against the raw coverage."
    },
    {
      "metadata": {
        "_uuid": "18d2aa182a44c65a87c75f41047c653a79bc1c3f",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2b13d1ecc7004832e8e042d034922796263054b7",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def cov_to_class(val):    \n    for i in range(0, 11):\n        if val * 10 <= i :\n            return i\n        \ntrain_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a5e66ff4809ea2f9a679b7ddbda5028dc324137a",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "fig, axs = plt.subplots(1, 2, figsize=(15,5))\nsns.distplot(train_df.coverage, kde=False, ax=axs[0])\nsns.distplot(train_df.coverage_class, bins=10, kde=False, ax=axs[1])\nplt.suptitle(\"Salt coverage\")\naxs[0].set_xlabel(\"Coverage\")\naxs[1].set_xlabel(\"Coverage class\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0dd39993eb2c7e77e5ce2d3388ea8ff1d581a670",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plt.scatter(train_df.coverage, train_df.coverage_class)\nplt.xlabel(\"Coverage\")\nplt.ylabel(\"Coverage class\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2391c568019151b098a002937516bb77a506f403"
      },
      "cell_type": "markdown",
      "source": "# Plotting the depth distributions\nSeparatelty plotting the depth distributions for the training and the testing data."
    },
    {
      "metadata": {
        "_uuid": "6ae7b7011b7de3caed58f9ca3939df15ffa319ad",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "sns.distplot(train_df.z, label=\"Train\")\nsns.distplot(test_df.z, label=\"Test\")\nplt.legend()\nplt.title(\"Depth distribution\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "14835b3e0eafd3a1c0e3a1f18a2e7979e75d3fa3"
      },
      "cell_type": "markdown",
      "source": "# Show some example images"
    },
    {
      "metadata": {
        "_uuid": "1a6bc85ee458f72c0917edf77895d5abc5eaf3ee",
        "scrolled": false,
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "max_images = 60\ngrid_width = 15\ngrid_height = int(max_images / grid_width)\nfig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width, grid_height))\nfor i, idx in enumerate(train_df.index[:max_images]):\n    img = train_df.loc[idx].images\n    mask = train_df.loc[idx].masks\n    ax = axs[int(i / grid_width), i % grid_width]\n    ax.imshow(img, cmap=\"Greys\")\n    ax.imshow(mask, alpha=0.3, cmap=\"Greens\")\n    ax.text(1, img_size_ori-1, train_df.loc[idx].z, color=\"black\")\n    ax.text(img_size_ori - 1, 1, round(train_df.loc[idx].coverage, 2), color=\"black\", ha=\"right\", va=\"top\")\n    ax.text(1, 1, train_df.loc[idx].coverage_class, color=\"black\", ha=\"left\", va=\"top\")\n    ax.set_yticklabels([])\n    ax.set_xticklabels([])\nplt.suptitle(\"Green: salt. Top-left: coverage class, top-right: salt coverage, bottom-left: depth\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "00655e32f93f96ebd90dbe94e35ee052f52217cd"
      },
      "cell_type": "markdown",
      "source": "# Create train/validation split stratified by salt coverage\nUsing the salt coverage as a stratification criterion. Also show an image to check for correct upsampling."
    },
    {
      "metadata": {
        "_uuid": "2d3c3157512d11e71ac74ce51a937b85bedfe1d1",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n    train_df.index.values,\n    np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n    np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n    train_df.coverage.values,\n    train_df.z.values,\n    test_size=0.2, stratify=train_df.coverage_class, random_state=1337)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f2f1ab00f03e71e6d7f9b2214408b5a9779fc235",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "tmp_img = np.zeros((img_size_target, img_size_target), dtype=train_df.images.loc[ids_train[10]].dtype)\ntmp_img[:img_size_ori, :img_size_ori] = train_df.images.loc[ids_train[10]]\nfix, axs = plt.subplots(1, 2, figsize=(15,5))\naxs[0].imshow(tmp_img, cmap=\"Greys\")\naxs[0].set_title(\"Original image\")\naxs[1].imshow(x_train[10].squeeze(), cmap=\"Greys\")\naxs[1].set_title(\"Scaled image\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "63ac58ab47921b4e4f54102e2c8b85fa318225f1"
      },
      "cell_type": "markdown",
      "source": "# TF Start!"
    },
    {
      "metadata": {
        "_uuid": "a517622135321d17e4aaad749def999205da358c",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "print('x_train.shape:', x_train.shape)\nprint('y_train.shape:', y_train.shape)\nprint('x_valid.shape:', x_valid.shape)\nprint('y_valid.shape:', y_valid.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f904bf915fdd672ba1ed90765f5e22216d26b7b1",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\ny_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "131b071610423a11b8852fc464ecd6e2e7e99ea2",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "print('x_train.shape:', x_train.shape)\nprint('y_train.shape:', y_train.shape)\nprint('x_valid.shape:', x_valid.shape)\nprint('y_valid.shape:', y_valid.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1aa78bd7c607e1f0e0235e4b2f82056c0361dac5",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "if 'isess' not in locals():\n    isess = tf.InteractiveSession()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "f438901d3285f3baeecd920ea230e4962a545285"
      },
      "cell_type": "code",
      "source": "import time\nimport os\nimport pandas as pd\nimport tensorflow as tf\n\n\ndef image_augmentation(image, mask):\n    \"\"\"Returns (maybe) augmented images\n\n    (1) Random flip (left <--> right)\n    (2) Random flip (up <--> down)\n    (3) Random brightness\n    (4) Random hue\n\n    Args:\n        image (3-D Tensor): Image tensor of (H, W, C)\n        mask (3-D Tensor): Mask image tensor of (H, W, 1)\n\n    Returns:\n        image: Maybe augmented image (same shape as input `image`)\n        mask: Maybe augmented mask (same shape as input `mask`)\n    \"\"\"\n    concat_image = tf.concat([image, mask], axis=-1)\n\n    maybe_flipped = tf.image.random_flip_left_right(concat_image)\n    maybe_flipped = tf.image.random_flip_up_down(concat_image)\n\n    image = maybe_flipped[:, :, :-1]\n    mask = maybe_flipped[:, :, -1:]\n\n    image = tf.image.random_brightness(image, 0.7)\n    image = tf.image.random_hue(image, 0.3)\n\n    return image, mask\n\n\ndef get_image_mask(queue, augmentation=True):\n    \"\"\"Returns `image` and `mask`\n\n    Input pipeline:\n        Queue -> CSV -> FileRead -> Decode JPEG\n\n    (1) Queue contains a CSV filename\n    (2) Text Reader opens the CSV\n        CSV file contains two columns\n        [\"path/to/image.jpg\", \"path/to/mask.jpg\"]\n    (3) File Reader opens both files\n    (4) Decode JPEG to tensors\n\n    Notes:\n        height, width = 640, 960\n\n    Returns\n        image (3-D Tensor): (640, 960, 3)\n        mask (3-D Tensor): (640, 960, 1)\n    \"\"\"\n    text_reader = tf.TextLineReader(skip_header_lines=1)\n    _, csv_content = text_reader.read(queue)\n\n    image_path, mask_path = tf.decode_csv(\n        csv_content, record_defaults=[[\"\"], [\"\"]])\n\n    image_file = tf.read_file(image_path)\n    mask_file = tf.read_file(mask_path)\n\n    image = tf.image.decode_jpeg(image_file, channels=3)\n    image.set_shape([640, 960, 3])\n    image = tf.cast(image, tf.float32)\n\n    mask = tf.image.decode_jpeg(mask_file, channels=1)\n    mask.set_shape([640, 960, 1])\n    mask = tf.cast(mask, tf.float32)\n    mask = mask / (tf.reduce_max(mask) + 1e-7)\n\n    if augmentation:\n        image, mask = image_augmentation(image, mask)\n\n    return image, mask\n\n\ndef conv_conv_pool(input_,\n                   n_filters,\n                   training,\n                   flags,\n                   name,\n                   pool=True,\n                   activation=tf.nn.relu):\n    \"\"\"{Conv -> BN -> RELU}x2 -> {Pool, optional}\n\n    Args:\n        input_ (4-D Tensor): (batch_size, H, W, C)\n        n_filters (list): number of filters [int, int]\n        training (1-D Tensor): Boolean Tensor\n        name (str): name postfix\n        pool (bool): If True, MaxPool2D\n        activation: Activaion functions\n\n    Returns:\n        net: output of the Convolution operations\n        pool (optional): output of the max pooling operations\n    \"\"\"\n    net = input_\n\n    with tf.variable_scope(\"layer{}\".format(name)):\n        for i, F in enumerate(n_filters):\n            net = tf.layers.conv2d(\n                net,\n                F, (3, 3),\n                activation=None,\n                padding='same',\n                kernel_regularizer=tf.contrib.layers.l2_regularizer(flags.reg),\n                name=\"conv_{}\".format(i + 1))\n            net = tf.layers.batch_normalization(\n                net, training=training, name=\"bn_{}\".format(i + 1))\n            net = activation(net, name=\"relu{}_{}\".format(name, i + 1))\n\n        if pool is False:\n            return net\n\n        pool = tf.layers.max_pooling2d(\n            net, (2, 2), strides=(2, 2), name=\"pool_{}\".format(name))\n\n        return net, pool\n\n\ndef upconv_concat(inputA, input_B, n_filter, flags, name):\n    \"\"\"Upsample `inputA` and concat with `input_B`\n\n    Args:\n        input_A (4-D Tensor): (N, H, W, C)\n        input_B (4-D Tensor): (N, 2*H, 2*H, C2)\n        name (str): name of the concat operation\n\n    Returns:\n        output (4-D Tensor): (N, 2*H, 2*W, C + C2)\n    \"\"\"\n    up_conv = upconv_2D(inputA, n_filter, flags, name)\n\n    return tf.concat(\n        [up_conv, input_B], axis=-1, name=\"concat_{}\".format(name))\n\n\ndef upconv_2D(tensor, n_filter, flags, name):\n    \"\"\"Up Convolution `tensor` by 2 times\n\n    Args:\n        tensor (4-D Tensor): (N, H, W, C)\n        n_filter (int): Filter Size\n        name (str): name of upsampling operations\n\n    Returns:\n        output (4-D Tensor): (N, 2 * H, 2 * W, C)\n    \"\"\"\n\n    return tf.layers.conv2d_transpose(\n        tensor,\n        filters=n_filter,\n        kernel_size=2,\n        strides=2,\n        kernel_regularizer=tf.contrib.layers.l2_regularizer(flags.reg),\n        name=\"upsample_{}\".format(name))\n\n\ndef make_unet(X, training, flags=None):\n    \"\"\"Build a U-Net architecture\n\n    Args:\n        X (4-D Tensor): (N, H, W, C)\n        training (1-D Tensor): Boolean Tensor is required for batchnormalization layers\n\n    Returns:\n        output (4-D Tensor): (N, H, W, C)\n            Same shape as the `input` tensor\n\n    Notes:\n        U-Net: Convolutional Networks for Biomedical Image Segmentation\n        https://arxiv.org/abs/1505.04597\n    \"\"\"\n    conv1, pool1 = conv_conv_pool(X, [8, 8], training, flags, name=1)\n    conv2, pool2 = conv_conv_pool(pool1, [16, 16], training, flags, name=2)\n    conv3, pool3 = conv_conv_pool(pool2, [32, 32], training, flags, name=3)\n    conv4, pool4 = conv_conv_pool(pool3, [64, 64], training, flags, name=4)\n    conv5 = conv_conv_pool(\n        pool4, [128, 128], training, flags, name=5, pool=False)\n\n    up6 = upconv_concat(conv5, conv4, 64, flags, name=6)\n    conv6 = conv_conv_pool(up6, [64, 64], training, flags, name=6, pool=False)\n\n    up7 = upconv_concat(conv6, conv3, 32, flags, name=7)\n    conv7 = conv_conv_pool(up7, [32, 32], training, flags, name=7, pool=False)\n\n    up8 = upconv_concat(conv7, conv2, 16, flags, name=8)\n    conv8 = conv_conv_pool(up8, [16, 16], training, flags, name=8, pool=False)\n\n    up9 = upconv_concat(conv8, conv1, 8, flags, name=9)\n    conv9 = conv_conv_pool(up9, [8, 8], training, flags, name=9, pool=False)\n\n    return tf.layers.conv2d(\n        conv9,\n        1, (1, 1),\n        name='final',\n        activation=tf.nn.sigmoid,\n        padding='same')\n\nclass Flags:\n    reg = 0.1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d254235ea38194adb5ac87836a876ef3c354729c",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# hyper parameters\nepochs = 10\nbatch_size = 32\n\n# tf Graph input\nX = tf.placeholder(tf.float32, [None, 128, 128, 1])\nY = tf.placeholder(tf.float32, [None, 128, 128, 1])\n\nflags = Flags()\nlogits = make_unet(X, training=tf.constant(True), flags=flags)\nprediction = tf.nn.softmax(logits)\n\n# Define loss and optimizer\n# change to `tf.metics.mean_squared_error` ...\nloss_op = tf.reduce_sum(\n    tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=Y))\noptimizer = tf.train.AdamOptimizer(learning_rate=0.001)\ntrain_op = optimizer.minimize(loss_op)\n\ninit = tf.global_variables_initializer()\n\n# Start training\n# with tf.Session() as sess:\nisess.run(init)\n\nfor e in range(epochs):\n    print(f'epoch: {e+1}')\n    shuffle_x, shuffle_y = shuffle(x_train, y_train)\n    iterations = np.int(np.ceil(shuffle_x.shape[0] / batch_size))\n\n    for step in tqdm(range(iterations)):\n        start = step * batch_size\n        stop = (step+1) * batch_size\n        batch_x, batch_y = shuffle_x[start:stop], shuffle_y[start:stop]\n\n        isess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n        loss_step = step+1\n        if loss_step % 10 == 0:\n            # Calculate batch loss and accuracy\n            loss = isess.run(loss_op, feed_dict={X: batch_x, Y: batch_y})\n            print(\"Step: {}, Minibatch Loss= {:.4f}\".format(str(loss_step), loss))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "46a932e73c2529a6fc2b258537ac84be8f36bc59"
      },
      "cell_type": "code",
      "source": "saver = tf.train.Saver()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "68b5eb82c1f5f0a621c525beeb2ecaf3c3fc23e4",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "save_path = saver.save(isess, \"/tmp/model.ckpt\")\nprint(\"Model saved in path: %s\" % save_path)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "33dd6c1b431feb83846ecdefa4dac69f8bb56425",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "predictions = isess.run(logits, feed_dict={X: x_valid})",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "21eb68b6dfa30738e75e0307014a6768f4d79280",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "loss = isess.run(loss_op, feed_dict={X: x_valid, Y: y_valid})\nloss",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fd973023204ebf921fe1f23748856e6a6f692aa4",
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "# Scoring\nScore the model and do a threshold optimization by the best IoU."
    },
    {
      "metadata": {
        "_uuid": "d261beec66b6867ac0d5c94684f12aa08b70d638",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# src: https://www.kaggle.com/aglotero/another-iou-metric\ndef iou_metric(y_true_in, y_pred_in, print_table=False):\n    labels = y_true_in\n    y_pred = y_pred_in\n    \n    true_objects = 2\n    pred_objects = 2\n\n    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n\n    # Compute areas (needed for finding the union between all objects)\n    area_true = np.histogram(labels, bins = true_objects)[0]\n    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n    area_true = np.expand_dims(area_true, -1)\n    area_pred = np.expand_dims(area_pred, 0)\n\n    # Compute union\n    union = area_true + area_pred - intersection\n\n    # Exclude background from the analysis\n    intersection = intersection[1:,1:]\n    union = union[1:,1:]\n    union[union == 0] = 1e-9\n\n    # Compute the intersection over union\n    iou = intersection / union\n\n    # Precision helper function\n    def precision_at(threshold, iou):\n        matches = iou > threshold\n        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n        return tp, fp, fn\n\n    # Loop over IoU thresholds\n    prec = []\n    if print_table:\n        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n    for t in np.arange(0.5, 1.0, 0.05):\n        tp, fp, fn = precision_at(t, iou)\n        if (tp + fp + fn) > 0:\n            p = tp / (tp + fp + fn)\n        else:\n            p = 0\n        if print_table:\n            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n        prec.append(p)\n    \n    if print_table:\n        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n    return np.mean(prec)\n\ndef iou_metric_batch(y_true_in, y_pred_in):\n    batch_size = y_true_in.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n        metric.append(value)\n    return np.mean(metric)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "85f6d9567cec0ef8976730a6834b6569b6e108a0",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "y_valid_ori = y_valid\npreds_valid = predictions\nthresholds = np.linspace(0, 1, 50)\nious = np.array([iou_metric_batch(y_valid_ori, np.int32(preds_valid > threshold)) for threshold in tqdm_notebook(thresholds)])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "183d37ad32bc2f1f0d17a9538702c45a826ccefc",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "threshold_best_index = np.argmax(ious[9:-10]) + 9\niou_best = ious[threshold_best_index]\nthreshold_best = thresholds[threshold_best_index]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8ced29761f2d1760245112a30a7abd4783b373dd",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plt.plot(thresholds, ious)\nplt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"IoU\")\nplt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\nplt.legend()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "332a614c0ae837c115ec6563f355753ffbb8cd83"
      },
      "cell_type": "markdown",
      "source": "# Submission\nLoad, predict and submit the test image predictions."
    },
    {
      "metadata": {
        "_uuid": "72128add82c6853441671fde67e7e66601a01787",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Source https://www.kaggle.com/bguberfain/unet-with-depth\ndef RLenc(img, order='F', format=True):\n    \"\"\"\n    img is binary mask image, shape (r,c)\n    order is down-then-right, i.e. Fortran\n    format determines if the order needs to be preformatted (according to submission rules) or not\n\n    returns run length as an array or string (if format is True)\n    \"\"\"\n    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n    runs = []  ## list of run lengths\n    r = 0  ## the current run length\n    pos = 1  ## count starts from 1 per WK\n    for c in bytes:\n        if (c == 0):\n            if r != 0:\n                runs.append((pos, r))\n                pos += r\n                r = 0\n            pos += 1\n        else:\n            r += 1\n\n    # if last run is unsaved (i.e. data ends with 1)\n    if r != 0:\n        runs.append((pos, r))\n        pos += r\n        r = 0\n\n    if format:\n        z = ''\n\n        for rr in runs:\n            z += '{} {} '.format(rr[0], rr[1])\n        return z[:-1]\n    else:\n        return runs",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3ecb152b492c7126d12c5ef2c701eec8ea3d86f1",
        "scrolled": false,
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "x_test = np.array([upsample(np.array(load_img(\"../input/test/images/{}.png\".format(idx), grayscale=True))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f278d0b87320c117b4ed7c116a991782b82ba5a7",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# preds_test = model.predict(x_test)\n# predictions = isess.run(logits, feed_dict={X: x_valid})\npreds_test = []\nfor i in range(x_test.shape[0]//1000):\n    start = i*1000\n    stop = (i+1)*1000\n    x = x_test[start:stop,:,:,]\n    preds_test.append(isess.run(logits, feed_dict={X: x}))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "06c1f7e066c75d3af4d085364827a6886fd710b9",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "len(preds_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "51eda0e3539d35bd5a7d2f466ce86aedbad4a1a2",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "preds_test[0].shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "017ae6a78db443246da29e910aa47393155d8994",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "preds_concat = np.concatenate([p for p in preds_test], axis=0)\npreds_concat.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "113f816f9db8b87ca7f6845fe6e61328ab606f41",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "pred_dict = {idx: RLenc(np.round(downsample(preds_concat[i]) > threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4243166f91c4bcb4da00208f4f53dd912dbb429f",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "sub = pd.DataFrame.from_dict(pred_dict, orient='index')\nsub.index.names = ['id']\nsub.columns = ['rle_mask']\nsub.to_csv('submission.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bd6ce9b4d5fc80a2502a43e80299d628fb5ffc42",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}